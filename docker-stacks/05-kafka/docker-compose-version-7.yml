version: '3.7'

x-default-opts: 
  &default-opts
  logging:
    options:
      max-size: "${SIMVA_LOGGING_MAX_FILE_SIZE}"
      max-file: "${SIMVA_LOGGING_MAX_FILES}"
  # driver: "gelf"
  # options:
  #   gelf-address: "udp://127.0.0.1:5000"

networks:
  traefik_services:
    external: true
  kafka_services:
    driver: bridge
    name: "${SIMVA_KAFKA_NETWORK:-kafka_services}"

## based on https://github.com/simplesteph/kafka-stack-docker-compose/blob/master/full-stack.yml
services:

###
### It is possible to use all conflueninc products during development if you just use 1 broker
### https://docs.confluent.io/current/control-center/installation/licenses.html#developer-license
###
### So it is possible to use Confluentinc control center during development.

# https://community.cloudera.com/t5/Support-Questions/Kafka-Best-Practices-KAFKA-JVM-PERFORMANCE-OPTS/td-p/207143
# http://kafka.apache.org/documentation.html#java

  kafka1:
    << : *default-opts
    image: ${SIMVA_CONFLUENT_PLATFORM_IMAGE:-confluentinc/cp-kafka}:${SIMVA_KAFKA_VERSION:-7.8.0}
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENERS: LISTENER_DOCKER_INTERNAL://0.0.0.0:19092,LISTENER_DOCKER_EXTERNAL://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1.${SIMVA_INTERNAL_DOMAIN:-internal.test}:19092,LISTENER_DOCKER_EXTERNAL://kafka1.${SIMVA_INTERNAL_DOMAIN:-internal.test}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      #KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      #KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      #KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      #KAFKA_JMX_PORT: 9101
      #KAFKA_JMX_HOSTNAME: kafka.${SIMVA_INTERNAL_DOMAIN:-internal.test}
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1.${SIMVA_INTERNAL_DOMAIN:-internal.test}:9093'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'

      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      CLUSTER_ID: "${KAFKA_CLUSTER_ID:-ITHASTOBEGENERATEDBEFORE}"
      #KAFKA_BROKER_ID: 1
      #KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      # WARN: this is for demo / dev purposes
      #KAFKA_HEAP_OPTS: "-Xms512m -Xmx512m"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ${SIMVA_DATA_HOME:-/home/vagrant/docker-stacks/data}/kafka/data/kafka1/data:/var/lib/kafka/data:rw
      - ${SIMVA_DATA_HOME:-/home/vagrant/docker-stacks/data}/kafka/data/kafka1/kraft-combined-logs:/tmp/kraft-combined-logs:rw
    hostname: kafka1.${SIMVA_INTERNAL_DOMAIN:-internal.test}
    networks:
      default:
        aliases:
          - kafka1.${SIMVA_INTERNAL_DOMAIN:-internal.test}
      kafka_services:
        aliases:
          - kafka1.${SIMVA_INTERNAL_DOMAIN:-internal.test}
      traefik_services:
        aliases:
          - kafka1.${SIMVA_INTERNAL_DOMAIN:-internal.test}
  
  schema-registry:
    << : *default-opts
    image: confluentinc/cp-schema-registry:7.8.0
    depends_on:
      - kafka1
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka1.${SIMVA_INTERNAL_DOMAIN:-internal.test}:19092
      SCHEMA_REGISTRY_HOST_NAME: schema-registry.${SIMVA_INTERNAL_DOMAIN:-internal.test}
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8085"
    volumes:
      - /etc/localtime:/etc/localtime:ro
    hostname: schema-registry.${SIMVA_INTERNAL_DOMAIN:-internal.test}
    networks:
      default:
        aliases:
          - schema-registry.${SIMVA_INTERNAL_DOMAIN:-internal.test}
      kafka_services:
        aliases:
          - schema-registry.${SIMVA_INTERNAL_DOMAIN:-internal.test}
  connect:
    << : *default-opts
    image: cnfldemos/kafka-connect-datagen:0.6.4-7.6.0
    command: >
      bash -c '
        confluent-hub install --no-prompt confluentinc/kafka-connect-s3:latest
        # Add extra jar files to all storage plugins
        cp -a /usr/share/simva/kafka-connect-storage-common/* /usr/share/confluent-hub-components/confluentinc-kafka-connect-s3/lib/;
        if [[ -e "$${SIMVA_CA_FILE}" ]]; then
          echo 1>&2 "Check if $${SIMVA_CA_FILE} is already imported into $${JDK_TRUSTORE}";
          keytool -list -keystore $${JDK_TRUSTORE} -storepass "$${JDK_TRUSTORE_PASSWORD}" -alias "$${SIMVA_CA_ALIAS}" >/dev/null 2>&1;
          ca_already_imported=$$?;
          if [[ $${ca_already_imported} -ne 0 ]]; then
            echo 1>&2 "Not imported, importing ...";
            launch_bash_options=$$-
            set +e
            keytool -importcert -trustcacerts -noprompt -keystore $${JDK_TRUSTORE} -storepass "$${JDK_TRUSTORE_PASSWORD}" -file "$${SIMVA_CA_FILE}" -alias "$${SIMVA_CA_ALIAS}" >/dev/null 2>&1;
            if [[ $$launch_bash_options =~ e ]]; then
              set -e
            fi
            echo 1>&2 "$${SIMVA_CA_FILE} imported";
          else
            echo 1>&2 "$${SIMVA_CA_FILE} already imported";
          fi;
        fi
        # Run
        exec /etc/confluent/docker/run;'
    environment:      
      # Bootstrap options
      # NOTE: To avoid to change the sourcecode we modify the JDK truststore so the AWS S3 client can connect to minio using a self-signed certificate
      JDK_TRUSTORE: "/usr/lib/jvm/zulu-8-amd64/jre/lib/security/cacerts"
      JDK_TRUSTORE_PASSWORD: "changeit"
      SIMVA_CA_ALIAS: "simvaCA"
      SIMVA_CA_FILE: "/usr/share/simva/ca/rootCA.pem"

      # Kafka connect options
      CONNECT_BOOTSTRAP_SERVERS: "kafka1.${SIMVA_INTERNAL_DOMAIN:-internal.test}:19092"
      CONNECT_REST_PORT: 8083
      CONNECT_LISTENERS: http://0.0.0.0:8083

      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_PRODUCER_CLIENT_ID: "connect-worker-producer"

      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status

      CONNECT_REPLICATION_FACTOR: 1
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1

      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"

      CONNECT_REST_ADVERTISED_HOST_NAME: connect.${SIMVA_INTERNAL_DOMAIN:-internal.test}
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_PLUGIN_PATH: '/usr/share/java,/etc/kafka-connect/jars,/usr/share/confluent-hub-components'

      # Reduce Connect memory utilization
      KAFKA_HEAP_OPTS: "-Xms256M -Xmx512M"
      # https://github.com/confluentinc/cp-demo/blob/${SIMVA_KAFKA_VERSION:-5.5.0}-post/docker-compose.yml
      KAFKA_JVM_PERFORMANCE_OPTS: -server -XX:+UseG1GC -XX:GCTimeRatio=1
                  -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20
                  -XX:MaxGCPauseMillis=10000 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent
                  -XX:MaxInlineLevel=15 -Djava.awt.headless=true

      #CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      #CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry.${SIMVA_INTERNAL_DOMAIN:-internal.test}:8085"
    volumes:
      - /etc/localtime:/etc/localtime:ro
      # kafka-connect plugins have their own classpath, so it is required to add manually extensions to storage
      - ${SIMVA_DATA_HOME:-/home/vagrant/docker-stacks/data}/kafka/connect/kafka-connect-storage-common:/usr/share/simva/kafka-connect-storage-common
      - ${SIMVA_CONFIG_HOME:-/home/vagrant/docker-stacks/config}/kafka/connect:/usr/share/simva
      - ${SIMVA_TLS_HOME?TLS home folder required}/ca:/usr/share/simva/ca
    depends_on:
      - kafka1
      - schema-registry
    hostname: connect.${SIMVA_INTERNAL_DOMAIN:-internal.test}
    networks:
      default:
        aliases:
          - connect.${SIMVA_INTERNAL_DOMAIN:-internal.test}
      traefik_services:
        aliases:
          - connect.${SIMVA_INTERNAL_DOMAIN:-internal.test}

  kafka-rest-proxy:
    image: confluentinc/cp-kafka-rest:7.8.0
    environment:
      KAFKA_REST_LISTENERS: http://0.0.0.0:8086/
      KAFKA_REST_SCHEMA_REGISTRY_URL: http://schema-registry.${SIMVA_INTERNAL_DOMAIN:-internal.test}:8085/
      KAFKA_REST_HOST_NAME: kafka-rest-proxy.${SIMVA_INTERNAL_DOMAIN:-internal.test}
      KAFKA_REST_BOOTSTRAP_SERVERS: PLAINTEXT://kafka1.${SIMVA_INTERNAL_DOMAIN:-internal.test}:19092
    depends_on:
      - kafka1
      - schema-registry
    volumes:
      - /etc/localtime:/etc/localtime:ro
    hostname: kafka-rest-proxy.${SIMVA_INTERNAL_DOMAIN:-internal.test}
    networks:
      default:
        aliases:
          - kafka-rest-proxy.${SIMVA_INTERNAL_DOMAIN:-internal.test}